#!/usr/bin/env python3

import os
import sys
import torch
import pickle

# ä¿®å¤OpenMPåº“å†²çªé”™è¯¯
os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from src.config import Config
from src.transformer import Transformer


class InteractiveTranslator:
    def __init__(self, checkpoint_path=None):
        self.config = Config()
        
        if checkpoint_path is None:
            checkpoint_path = "./checkpoints/best_model.pth"
        
        if not os.path.exists(checkpoint_path):
            print(f"é”™è¯¯: æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶ {checkpoint_path}")
            sys.exit(1)
        
        # åŠ è½½æ¨¡å‹
        self.model, self.src_tokenizer, self.tgt_tokenizer = self.load_model(checkpoint_path)
        print("æ¨¡å‹åŠ è½½æˆåŠŸ!")
        
        # æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
        self.display_model_info()
    
    def safe_load_checkpoint(self, checkpoint_path):
        
        try:
            # é¦–å…ˆå°è¯•ä½¿ç”¨weights_only=False
            checkpoint = torch.load(checkpoint_path, map_location=self.config.device, weights_only=False)
            return checkpoint
        except Exception as e:
            print(f"æ ‡å‡†åŠ è½½å¤±è´¥: {e}")
            print("å°è¯•æ›¿ä»£åŠ è½½æ–¹æ³•...")
            
            # æ›¿ä»£æ–¹æ³•ï¼šæ‰‹åŠ¨åŠ è½½
            try:
                with open(checkpoint_path, 'rb') as f:
                    checkpoint = pickle.load(f)
                return checkpoint
            except Exception as e2:
                print(f"æ›¿ä»£åŠ è½½ä¹Ÿå¤±è´¥: {e2}")
                raise
    
    def load_model(self, checkpoint_path):
        """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
        print(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {checkpoint_path}")
        checkpoint = self.safe_load_checkpoint(checkpoint_path)
        
        # ä»æ£€æŸ¥ç‚¹æ¢å¤åˆ†è¯å™¨
        src_tokenizer = checkpoint['src_tokenizer']
        tgt_tokenizer = checkpoint['tgt_tokenizer']
        
        # åˆå§‹åŒ–æ¨¡å‹ - ä½¿ç”¨ä¸è®­ç»ƒæ—¶ç›¸åŒçš„max_seq_length
        model = Transformer(
            src_vocab_size=src_tokenizer.get_vocab_size(),
            tgt_vocab_size=tgt_tokenizer.get_vocab_size(),
            d_model=self.config.d_model,
            nhead=self.config.nhead,
            num_encoder_layers=self.config.num_encoder_layers,
            num_decoder_layers=self.config.num_decoder_layers,
            dim_feedforward=self.config.dim_feedforward,
            dropout=0.0,  # æ¨ç†æ—¶å…³é—­dropout
            max_seq_length=100  # ä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´
        ).to(self.config.device)
        
        # åŠ è½½æ¨¡å‹æƒé‡ - å¿½ç•¥ä½ç½®ç¼–ç çš„å¤§å°ä¸åŒ¹é…
        model_state_dict = model.state_dict()
        checkpoint_state_dict = checkpoint['model_state_dict']
        
        # è¿‡æ»¤æ‰ä½ç½®ç¼–ç çš„æƒé‡ï¼Œå› ä¸ºå¤§å°ä¸åŒ¹é…
        filtered_checkpoint_state_dict = {}
        for key, value in checkpoint_state_dict.items():
            if 'pos_encoding' not in key:
                filtered_checkpoint_state_dict[key] = value
            else:
                print(f"è·³è¿‡ä½ç½®ç¼–ç æƒé‡: {key}")
        
        # åŠ è½½è¿‡æ»¤åçš„çŠ¶æ€å­—å…¸
        model.load_state_dict(filtered_checkpoint_state_dict, strict=False)
        model.eval()
        
        return model, src_tokenizer, tgt_tokenizer
    
    def display_model_info(self):
        """æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯"""
        total_params = sum(p.numel() for p in self.model.parameters())
        print(f"\næ¨¡å‹ä¿¡æ¯:")
        print(f"- æºè¯­è¨€è¯æ±‡è¡¨å¤§å°: {self.src_tokenizer.get_vocab_size()}")
        print(f"- ç›®æ ‡è¯­è¨€è¯æ±‡è¡¨å¤§å°: {self.tgt_tokenizer.get_vocab_size()}")
        print(f"- æ¨¡å‹æ€»å‚æ•°: {total_params:,}")
        print(f"- è¿è¡Œè®¾å¤‡: {self.config.device}")
        print("-" * 50)
    
    def preprocess_text(self, text):
        """é¢„å¤„ç†è¾“å…¥æ–‡æœ¬"""
        # ç®€å•çš„æ–‡æœ¬æ¸…ç†
        text = text.strip()
        if not text:
            return ""
        # ç¡®ä¿å¥å­ä»¥æ ‡ç‚¹ç»“å°¾
        if text[-1] not in ['.', '!', '?']:
            text += '.'
        return text
    
    def translate(self, text, max_length=50):
        """ç¿»è¯‘å•ä¸ªå¥å­"""
        if not text:
            return ""
        
        # é¢„å¤„ç†æ–‡æœ¬
        text = self.preprocess_text(text)
        
        try:
            # ç¼–ç æºæ–‡æœ¬
            src_encoding = self.src_tokenizer.encode(text)
            src_ids = [self.src_tokenizer.token_to_id("[SOS]")] + src_encoding.ids[:self.config.max_length-2] + [self.src_tokenizer.token_to_id("[EOS]")]
            src_tensor = torch.tensor(src_ids, dtype=torch.long).unsqueeze(0).to(self.config.device)
            
            # åˆ›å»ºæºè¯­è¨€æ©ç 
            src_mask = (src_tensor != 0).unsqueeze(1).unsqueeze(2)
            
            # å¼€å§‹ç¿»è¯‘ï¼ˆå¼€å§‹æ—¶åªæœ‰[SOS]ï¼‰
            tgt_ids = [self.tgt_tokenizer.token_to_id("[SOS]")]
            
            with torch.no_grad():
                # ç¼–ç å™¨å‰å‘ä¼ æ’­ï¼ˆä¸€æ¬¡æ€§è®¡ç®—ï¼‰
                memory = self.model.encode(src_tensor, src_mask)
                
                # è§£ç å™¨é€æ­¥ç”Ÿæˆ
                for i in range(max_length):
                    tgt_tensor = torch.tensor(tgt_ids, dtype=torch.long).unsqueeze(0).to(self.config.device)
                    
                    # åˆ›å»ºç›®æ ‡è¯­è¨€æ©ç 
                    tgt_len = len(tgt_ids)
                    tgt_mask = torch.tril(torch.ones(tgt_len, tgt_len, device=self.config.device))
                    tgt_mask = tgt_mask.unsqueeze(0).unsqueeze(1)
                    
                    # è§£ç å™¨å‰å‘ä¼ æ’­
                    output = self.model.decode(tgt_tensor, memory, tgt_mask, src_mask)
                    
                    # è·å–ä¸‹ä¸€ä¸ªtokenï¼ˆä½¿ç”¨è´ªå¿ƒæœç´¢ï¼‰
                    next_token_id = output[0, -1, :].argmax().item()
                    tgt_ids.append(next_token_id)
                    
                    # å¦‚æœé‡åˆ°[EOS]åˆ™åœæ­¢
                    if next_token_id == self.tgt_tokenizer.token_to_id("[EOS]"):
                        break
            
            # è§£ç ç›®æ ‡æ–‡æœ¬
            decoded_tokens = []
            for token_id in tgt_ids[1:]:  # è·³è¿‡[SOS]
                if token_id == self.tgt_tokenizer.token_to_id("[EOS]"):
                    break
                if token_id not in [self.tgt_tokenizer.token_to_id("[PAD]"), 
                                  self.tgt_tokenizer.token_to_id("[SOS]"),
                                  self.tgt_tokenizer.token_to_id("[EOS]")]:
                    decoded_tokens.append(token_id)
            
            if not decoded_tokens:
                return "[ç¿»è¯‘å¤±è´¥]"
            
            translation = self.tgt_tokenizer.decode(decoded_tokens)
            return translation
            
        except Exception as e:
            print(f"ç¿»è¯‘è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
            return f"[ç¿»è¯‘é”™è¯¯: {str(e)}]"
    
    def interactive_mode(self):
        """äº¤äº’å¼ç¿»è¯‘æ¨¡å¼"""
        print("\nğŸ¯ äº¤äº’å¼ç¿»è¯‘æ¨¡å¼å·²å¯åŠ¨!")
        print("è¾“å…¥è‹±æ–‡å¥å­ï¼Œæ¨¡å‹å°†è¿”å›å¾·æ–‡ç¿»è¯‘")
        print("è¾“å…¥ 'quit' æˆ– 'exit' é€€å‡ºç¨‹åº")
        print("è¾“å…¥ 'examples' æŸ¥çœ‹ç¤ºä¾‹")
        print("-" * 50)
        
        while True:
            try:
                user_input = input("\nğŸ“ è¯·è¾“å…¥è‹±æ–‡: ").strip()
                
                if user_input.lower() in ['quit', 'exit', 'é€€å‡º']:
                    print("æ„Ÿè°¢ä½¿ç”¨ç¿»è¯‘å·¥å…·!")
                    break
                
                elif user_input.lower() in ['examples', 'ç¤ºä¾‹']:
                    self.show_examples()
                    continue
                
                elif not user_input:
                    continue
                
                # ç¿»è¯‘
                print("ğŸ”„ ç¿»è¯‘ä¸­...")
                translation = self.translate(user_input)
                print(f"ğŸ‡©ğŸ‡ª å¾·æ–‡ç¿»è¯‘: {translation}")
                
            except KeyboardInterrupt:
                print("\n\næ„Ÿè°¢ä½¿ç”¨ç¿»è¯‘å·¥å…·!")
                break
            except Exception as e:
                print(f"ç¿»è¯‘è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
    
    def show_examples(self):
        """æ˜¾ç¤ºç¿»è¯‘ç¤ºä¾‹"""
        examples = [
            "Hello, how are you?",
            "I love machine learning.",
            "What is your name?",
            "The weather is beautiful today.",
            "Can you help me with this problem?",
            "Artificial intelligence is changing the world."
        ]
        
        print("\nğŸ“š ç¿»è¯‘ç¤ºä¾‹:")
        print("-" * 40)
        for example in examples:
            translation = self.translate(example)
            print(f"EN: {example}")
            print(f"DE: {translation}")
            print()


def main():
    """ä¸»å‡½æ•°"""
    print(" Transformeräº¤äº’å¼ç¿»è¯‘å·¥å…· (ä¿®å¤ä½ç½®ç¼–ç é—®é¢˜)")
    print("=" * 50)
    
    import argparse
    
    parser = argparse.ArgumentParser(description='Transformerè‹±å¾·ç¿»è¯‘å·¥å…·')
    parser.add_argument('--model', '-m', type=str, default='./checkpoints/best_model.pth',
                       help='æ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„')
    
    args = parser.parse_args()
    
    # åˆå§‹åŒ–ç¿»è¯‘å™¨
    translator = InteractiveTranslator(args.model)
    
    # è¿è¡Œäº¤äº’å¼ç¿»è¯‘æ¨¡å¼
    translator.interactive_mode()


if __name__ == "__main__":
    main()